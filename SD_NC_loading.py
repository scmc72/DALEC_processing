# functions to load and plot netCDF data generated by acolite processor (currently using for planet data)
# note: some functions might not be fully tested yet... I cannae remember where I got up to with these...
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import dalecLoad
import spectralConv
import SD_raster_loading
import os
import netCDF4
from matplotlib.dates import DateFormatter
import matplotlib.dates as mdates
from datetime import datetime

def getclosest_ij(lats, lons, latpt, lonpt):
    '''
    a function to find the index of the point closest pt
    (in squared distance) to give lat/lon value.
    '''
    # find squared distance of every point on grid
    dist_sq = (lats-latpt)**2 + (lons-lonpt)**2
    # 1D index of minimum dist_sq element
    minindex_flattened = dist_sq.argmin()
    # Get 2D index for latvals and lonvals arrays from 1D index
    return np.unravel_index(minindex_flattened, lats.shape)


def get_SD_NC_Spectra(NC_file, lat_pt, lon_pt):
    '''
    function to extract surface reflectance spectra from a superdoves NetCDF file at a given lat_pt, lon_pt coordinate
    
    to load ncdf file do this: netCDF4.Dataset(directory+file)
    '''
    lat, lon = NC_file.variables['lat'][:], NC_file.variables['lon'][:]
    iy, ix = getclosest_ij(lat, lon, lat_pt, lon_pt)
    #print(iy, ix)
    wavelengths = []
    rhos = []
    for var in list(NC_file.variables.keys()):
        # only interested in surface reflectance:
        if 'rhos' in var:
            wavelengths.append(float(var[5:]))
            rhos.append(NC_file.variables[var][iy, ix])
    
    df = pd.DataFrame(data={'Wavelength':wavelengths,
                     'Rho_s':rhos})
    return df


def get_SD_NC_Spectra_grid(NC_file, lat_pt, lon_pt, shape=(3, 3)):
    '''
    function to extract surface reflectance spectra from a superdoves NetCDF file at a given lat_pt, lon_pt coordinate
    gets values from several pixels in a grid (with shape = shape) around the chosen coord
    '''
    lat, lon = NC_file.variables['lat'][:], NC_file.variables['lon'][:]
    iy, ix = getclosest_ij(lat, lon, lat_pt, lon_pt)

    # get wavelengths data and create df for this
    wavelengths = []    
    for var in list(NC_file.variables.keys()):
        # only interested in surface reflectance:
        if 'rhos' in var:
            wavelengths.append(float(var[5:]))
            
    df1 = pd.DataFrame(data={'Wavelength':wavelengths})
                       
    # generate x and y coords for grid with shape=(shape[0], shape[1])
    x = np.linspace(ix - shape[0]//2,
                    ix + shape[0]//2 - (1 - shape[0]%2),
                    shape[0],
                    dtype=int)
    y = np.linspace(iy - shape[1]//2,
                    iy + shape[1]//2 - (1 - shape[1]%2),
                    shape[1],
                    dtype=int)
    rhos = []
    for i in x:
        for j in y:
            for var in list(NC_file.variables.keys()):
                # only interested in surface reflectance:
                if 'rhos' in var:
                    rhos.append(NC_file.variables[var][j, i])
            # might want to think about if I want to include the lat and lon of each pixel too?
            var_name = 'rho_s_' + str(i) + '_' + str(j)
            df2 = pd.DataFrame(data={var_name:rhos})
            df1 = pd.concat([df1, df2], axis=1)
            rhos = []
    return df1

def load_multiple_SDs(SD_directory, coord, pixel_grid_shape=(1, 1), div_by_pi=True, skipSameDay=True):
    '''
    Loads all L2R netcdfs in a given directory. Then extracts a grid of shape=pixel_grid_shape at the given coord
    Returns a pandas DF with Date, Wavelength, and rho_s columns
    Note that the rho_s columns will be formatted as per `SD_NC_loading.get_SD_NC_Spectra_grid()`
    option div_by_pi will change the units to match the DALEC units
    skipSameDay will skip images which are from the same day, using the earliest image.
    '''
    # could use list comprehensions in a few places here if things start getting slow!
    SD_files = []
    for file in os.listdir(SD_directory):
        if file.endswith("L2R.nc"):
            SD_files.append(os.path.join(SD_directory, file))

    ncdf_dates = []
    indexes = []
    SD_spect_list = []

    for i in range(len(SD_files)):
        f = netCDF4.Dataset(SD_files[i])
        SD_spect = get_SD_NC_Spectra_grid(f, coord[0], coord[1], shape=(3, 3))
        ncdf_dates.append(f.isodate)
        indexes.append(i)
        SD_spect_list.append(SD_spect)
    
    # currently my code which removes images from the same date relies on the images being sorted in date order ...
    SD_spect_list_sorted = [x for _, x in sorted(zip(ncdf_dates, SD_spect_list))]
    sorted_dates = sorted(ncdf_dates)
    
    SD_df = None # this is almost definitely uneccesary
    
    # perhaps have removing images from same date as an option??
    for i in range(len(SD_spect_list_sorted)):
        SD_spect = SD_spect_list_sorted[i]
        date = sorted_dates[i]
        if (date[:10] == sorted_dates[i-1][:10]) and skipSameDay:
            print('...skipping duplicate date entry on ' + str(date[:10]) + 
                  ' (set skipSameDay=False to disable this)')
        else:
            SD_df_tmp = SD_spect.copy()
            SD_df_tmp['Date'] = pd.to_datetime(date)
            SD_df_tmp['Date'] = SD_df_tmp['Date'].dt.date # just removes the time aspect from the variable
            SD_df_tmp.set_index(['Date', 'Wavelength'], inplace=True)
            if SD_df is None:
                SD_df = SD_df_tmp.copy()
            else:
                SD_df = pd.concat([SD_df, SD_df_tmp])

    if div_by_pi:
        SD_df = SD_df.div(np.pi)
    # don't really need to sort, but in case I change something its good to have:
    return SD_df.sort_values(['Date', 'Wavelength'])

def load_SD_summarise_multiple_DALEC_days(DALEC_directory, RSR_doves_file='non-DALEC-data/RSR-Superdove.csv',
                                          file_names=None, dalec_summary_function=dalecLoad.uniform_grid_spectra_mean,
                                          DALEC_col_name='DALEC_mean_Rrs', dateOnly=True):
    '''
    Loads multiple DALEC log files and then carries out the specified daily summary operation on these.
    Then resamples to superdoves wavebands and saves the data in a nice dataframe with Date, Wavelength and DALEC_col_name
    dateOnly removes the time aspect from the Date column
    '''
    supported_functions = [dalecLoad.uniform_grid_spectra_mean]
    if dalec_summary_function not in supported_functions:
        print("I've not tested this summary function yet! It might not (probably won't) work! ")
    
    RSR_doves = pd.read_csv(RSR_doves_file)
    
    if file_names is None: # if None, then load all DALEC transect (.dtf) files in the directory
        DALEC_files = []
        for file in os.listdir(DALEC_directory):
            if file.endswith(".dtf"):
                DALEC_files.append(os.path.join(DALEC_directory, file))
    else:
        DALEC_files = [DALEC_directory + file for file in file_names]

    DALEC_df = None # just initialise as None idk
    
    # assuming that the spectral wavelength info is the same for each file
    # this is almost definitely always the case... (unless perhaps we used a different DALEC?)
    spect_wavelengths = dalecLoad.load_DALEC_spect_wavelengths(DALEC_files[0])
    # would be a bit nicer to not hard code these, but would require also reading a SD file
    # see SD_NC_loading.get_SD_NC_Spectra() for how to do this
    doves_wavelengths = [444., 492., 533., 566., 612., 666., 707., 866.]
    
    # as we know, loading DALEC files isnae that fast...
    # currently some weird stuff will happen if we include log files which are from serial output
    # basically need dalecLoad.load_DALEC_log() to be super robust for this to work! 
    for file in DALEC_files:
        print('loading ... ' + str(file))
        dalec_log = dalecLoad.load_DALEC_log(file)
        mean_spect = dalec_summary_function(dalec_log, spect_wavelengths)
        DALEC_SD = spectralConv.SD_band_calc(RSR_doves, mean_spect['Rrs_mean'].values,
                                             RSR_doves['Wavelength (nm)'].values)
        DALEC_df_tmp = pd.DataFrame(data=DALEC_SD, columns=[DALEC_col_name])
        DALEC_df_tmp['Date'] = pd.to_datetime(dalec_log[' UTC Date'].iloc[0])
        if dateOnly:
            DALEC_df_tmp['Date'] = DALEC_df_tmp['Date'].dt.date # just removes the time aspect from the variable
        DALEC_df_tmp['Wavelength'] = doves_wavelengths
        DALEC_df_tmp.set_index(['Date', 'Wavelength'], inplace=True)
        if DALEC_df is None:
            DALEC_df = DALEC_df_tmp.copy()
        else:
            DALEC_df = pd.concat([DALEC_df, DALEC_df_tmp])
            
    # probably smart to sort in case we get some weird stuff happenin' with file order etc.
    return DALEC_df.sort_values(['Date', 'Wavelength'])


def join_DALEC_SD_dfs(DALEC_df, SD_df, dropNA=True):
    '''
    Just a super simple function so I don't forget how to join dataframes together lol
    takes a DALEC_df created by load_SD_summarise_multiple_DALEC_days and a SD_df created with load_multiple_SDs
    and joins 'em
    dropNA removes dates where there is no date overlap between DALEC and SD data
    in future this might become more complex if I have different summary functions or if I want to match up data which
    isn't from the same day
    '''
    if dropNA:
        superDuperDF = DALEC_df.join(SD_df, on=['Date', 'Wavelength']).dropna()
    else:
        superDuperDF = DALEC_df.join(SD_df, on=['Date', 'Wavelength'])
        
    return superDuperDF


def multiDaySpectraPlot(superDuperDF, DALEC_param='DALEC_mean_Rrs', SD_col_slice=slice(1, None, 1),
                        figsize=None, SD_label='SD_Spectra', ylim=None, grid=True, show_plot=True):
    '''
    takes a DF, superDuperDF, with columns 'Date', 'Wavelength', DALEC_param, and SD data which is selected using SD_col_slice
    superDuperDF can be created with join_DALEC_SD_dfs()
    
    generates a series of Rrs vs wavelength plots for each date in the DF 
    '''
    # if I want more flexibility then I could try using some **kwargs?
    # would need to decide which plot call these would be for... - both?

    n_dates = len(superDuperDF.index.get_level_values(0).unique())
    n_rows = int(np.sqrt(n_dates)//1)
    n_cols = int(np.ceil(n_dates/n_rows))
    
    if figsize is None:
        figsize = (n_cols * 7, n_rows*7)

    fig, ax = plt.subplots(n_rows, n_cols, figsize=figsize)
    ax = ax.flatten()

    for i, date in zip(range(n_dates), superDuperDF.index.get_level_values(0).unique()):
        x = superDuperDF.index.get_level_values(1).unique()
        y = superDuperDF.loc[[date]][DALEC_param].values
        ax[i].plot(x, y, label=DALEC_param)
        for col in list(superDuperDF.columns.values)[SD_col_slice]:
            y = superDuperDF.loc[[date]][col].values
            ax[i].plot(x, y,
                       color='red',
                       label=SD_label,
                       marker='o',
                       alpha=0.2)
        if ylim is None:
            ylim = [0., superDuperDF.max(axis=0).max()*1.1]
        ax[i].set_ylim(ylim)
            
        ax[i].set_title(str(date))

        ax[i].set_xlabel('Wavelength (nm)')
        ax[i].set_ylabel('$R_{rs}$ $(sr^{-1}$)')

        # this code removes duplicate labels in the legend. Naughty
        handles, labels = ax[i].get_legend_handles_labels()
        newLabels, newHandles = [], []
        for handle, label in zip(handles, labels):
            if label not in newLabels:
                newLabels.append(label)
                newHandles.append(handle)
        ax[i].legend(newHandles, newLabels)
        if grid:
            ax[i].grid()
    if show_plot:
        plt.show()
    return fig, ax
    


def Plot_matchUp_SD_DALEC(DALEC_log, spect_wavelengths, RSR_doves, NC_file, lat_pt, lon_pt,
                          shape=(3, 3), ax=None, showPlot=False):
    '''
    does basic plot of DALEC data vs SD data
    '''
    SD_spect = get_SD_NC_Spectra_grid(NC_file, lat_pt, lon_pt, shape=shape)
    
    if ax is None:
        ax = plt.gca()
    # do plotting
    print('warning: this is gonna be super duper slow for lots of samples :)')
    for sample in DALEC_log.index.get_level_values('Sample #').unique():
        dalec_SD = spectralConv.SD_Rrs(RSR_doves,
                                       DALEC_log.loc[sample],
                                       spect_wavelengths)
        ax.plot(dalec_SD['Wavelength'],
                 dalec_SD['Rrs'],
                 marker='o',
                 alpha=0.2,
                 color='blue',
                 label='DALEC')

    for col in list(SD_spect.columns.values)[1:]:
        ax.plot(SD_spect['Wavelength'],
                 SD_spect[col]/np.pi,
                 color='red',
                 label='SuperDoves Acolite',
                 marker='o',
                 alpha=0.2)

    plt.rc('axes', labelsize=14) #fontsize of the x and y labels
    plt.rc('legend', fontsize=14) #fontsize of the legend

    # this code removes duplicate labels in the legend. thanks stackoverflow!
    handles, labels = ax.get_legend_handles_labels()
    newLabels, newHandles = [], []
    for handle, label in zip(handles, labels):
        if label not in newLabels:
            newLabels.append(label)
            newHandles.append(handle)
    ax.legend(newHandles, newLabels)

    ax.set_xlabel('Wavelength (nm)')
    ax.set_ylabel('$R_{rs}$ $(sr^{-1}$)')
    ax.grid()
    if showPlot:
        plt.show()
        
def plot_multiDay_SD_DALEC_matchup(superDuperDF, DALEC_param='DALEC_mean_Rrs', SD_col_slice=slice(1, None, 1),
                                   figsize=(26, 13), SD_label='SD_Spectra', grid=True, cbar=True,
                                   x_y_line=True, show_plot=True):
    '''
    generates Rrs-insitu vs Rrs-SD plots for all SD wavebands with a given DF with Date, Wavelength columns 
    '''
    fig, ax = plt.subplots(2, 4, figsize=figsize)

    ax = ax.flatten()
    
    timestamps = [datetime.combine(date, datetime.min.time()).timestamp() \
                  for date in list(superDuperDF.index.get_level_values(0).unique())]    
    
    for i, wavelength in zip(range(8), superDuperDF.index.get_level_values(1).unique()):
        x = superDuperDF.loc[(superDuperDF.index.get_level_values(0)[:],wavelength), :][DALEC_param].values
        
        for col in list(superDuperDF.columns.values)[SD_col_slice]:
            y = superDuperDF.loc[(superDuperDF.index.get_level_values(0)[:],wavelength), :][col].values
            sc = ax[i].scatter(x, y,
                               c=timestamps,
                               cmap='jet',
                               marker='o',
                               alpha=0.5)

        ax[i].set_title('$\lambda = $' + str(wavelength) + ' nm')

        ax[i].set_xlabel('DALEC Rrs')
        ax[i].set_ylabel('SD Rrs')
        
        if cbar:
            fig.subplots_adjust(right=0.8)
            cbar_ax = fig.add_axes([0.82, 0.15, 0.03, 0.7])

            cbar = fig.colorbar(sc, cbar_ax, ticks=[min(timestamps), max(timestamps)])
            cbarTickLabels = (datetime.fromtimestamp(min(timestamps)).strftime("%d-%b"),
                              datetime.fromtimestamp(max(timestamps)).strftime("%d-%b"))
            cbar.ax.set_yticklabels(cbarTickLabels)

        if grid:
            ax[i].grid()
        
        # making the plots nice 'n' square and make sure they all have same scale
        max_xy = np.max([x, y])
        ax[i].set_ylim([0, max_xy*1.2])
        ax[i].set_xlim([0, max_xy*1.2])
        ax[i].set_aspect('equal', adjustable='box')

        if x_y_line:
            ax[i].plot([-1, 1], [-1, 1], 'k--', alpha=0.5)

    if show_plot:
        plt.show()
    return fig, ax, cbar

def NDPCI(Rrs_707, Rrs_612, alpha=46.478, beta=5.1864):
    '''
    using gomez et al 2011 normalized difference phycocyanin index (NDPCI) algorithm
    see: https://link.springer.com/article/10.1007/s10661-010-1831-7
    where PC [mg/m^3] = alpha * e ^ (beta * diff_ratio)
    and diff_ratio = (Rrs_709 - Rrs_620)/(Rrs_709 + Rrs_620)
    BUT for SD bands we use 707 and 612... should still work right?
    currently default params are those found in gomez et al 2011
    '''
    diff_ratio = (Rrs_707 - Rrs_612)/(Rrs_707 + Rrs_612)
    PC = alpha * np.exp(np.array(beta * diff_ratio, dtype=float)) # just force this to be a float array to make np.exp() happy
    return PC

def NDPCI_from_DF(df, col_name='DALEC_mean_Rrs', alpha=46.478, beta=5.1864):
    '''
    convenience function to extract Rrs_707 and Rrs_612 from a superduperdf kinda df and use this to call NDPCI()
    '''
    Rrs_612 = df.loc[(df.index.get_level_values(0)[:],612.0), :][col_name].values
    Rrs_707 = df.loc[(df.index.get_level_values(0)[:],707.0), :][col_name].values
    return NDPCI(Rrs_707, Rrs_612, alpha=alpha, beta=beta)

def plot_algorithm_from_DF(df, algorithm=NDPCI_from_DF, col_names=None, show_legend=False,
                           y_label='PC (mg m $^{-3}$)', grid=True,
                           plot_show=True, date_format='%d-%b', 
                           dailyTicks=True, date_label='Date (DD-MMM)', **kwargs):
    '''
    applies the chosen algorithm to the selected columns of the DF and plots the results
    if no column names are specified, then all columns will be processed and plotted
    '''
    if col_names is None:
        col_names = list(df.columns.values)
    results = [algorithm(df, col_name=col, **kwargs) for col in col_names]
    
    x = df.index.get_level_values(0).unique() # x is the list of dates
    
    for result, col_name in zip(results, col_names):
        plt.plot(x, result, label=col_name, marker='o', alpha=0.8)
        
    plt.xticks(rotation = 45)
    plt.xlabel(date_label)
    plt.ylabel(y_label)

    ax = plt.gca()
    date_form = DateFormatter(date_format)
    ax.xaxis.set_major_formatter(date_form) # set format
    if dailyTicks:
        ax.xaxis.set_major_locator(mdates.DayLocator(interval=1)) # make sure that ticks only appear daily
    if grid:
        ax.grid()
    if show_legend:
        plt.legend()
    if plot_show:
        plt.show()
    return ax